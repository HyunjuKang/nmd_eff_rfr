
### W1 \& Q2: Clarity of disscusion

Thank you for your constructive comment. In our experiments, Baseline 1hop-3N demonstrated the highest $Precision$ on BA-Shapes and Tree-Cycles, while 1hop-2N showed similar performance on Tree-Grids. $Precision$ indicates the fraction of the ground truth edges among the generated explanations. This suggests that connections within a 1-hop range in the graph are highly likely to be part of important subgraphs or ground truth. The reason behind this is that GNNs such as GraphSAGE rely on propagating information between neighboring nodes to update node representations. Since nodes within 1-hop are direct passage, the diminished propagation effect is likely to be more significant than distant neighboring nodes. In general, $Precision$ tends to be higher for smaller subgraphs, so such compact sizes of subgraphs as 1hop-3N and 1hop-2N can easily obtain the highest $Precision$. Thus, $Recall$ which indicates the fraction of the generated explanations among ground truth should be considered to measure how explanations describe ground truth closely. However, both 1hop-2N and 1hop-3N exhibited lower $Recall$ than UNR-Explainer, indicating that these baselines may miss covering the ground truth due to their limited exploration of distant but significant edges.

### W2 \& Q1: More discussion of choosing $k$

we recommend that practitioners choose $k$ to match the important range of $k$-hop in the embedding space, together with taking into account downstream tasks. A wider range of top- $k$ in $Importance$ enforces the explanation that brings signification changes in a wider neighborhood and consequently, the change of top-$k$ neighboring nodes affects related downstream tasks in Table 2, 3. Setting such a wider range of top- $k$ does not make sense considering the downstream tasks such as top- $k$ link prediction. We conduct the top-5 link-prediction tasks in a general setting. For the above reason, we set $k$ as $5$ in our experiments as unified settings.

Additionally, We conduct experiments on the CiteSeer dataset to observe the effect of top-$k$ regarding $imporance$. As shown in this attached [figure] (https://anonymous.4open.science/r/unr0929/neighbor_cnt.jpg), importance by top-$k$ differs by datasets. On the Cora dataset, Importance decreases as $k$ increases, which means that a node of interest still has a similar distance with distant neighbor nodes. However, on the CiteSeer dataset, the importance is less affected by $k$, which means that a node of interest totally changes the neighborhood. We assume that this is due to the degree of the input graph. CiteSeer has an average degree of around 2, while Cora has an average degree of around 3. Thus, a more sparse graph such as CiteSeer has more effect from the perturbation by locating different neighborhoods because we observe that a wider range of top-$k$ shows a similar level of $Importance$.
